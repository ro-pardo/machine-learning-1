{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "name": "",
  "signature": "sha256:9ea4166a3848d311b291c82e5aeaf40ebd8d1ee3b97496b1427c73019593166b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Fisher Linear Discriminant\n",
      "\n",
      "In this exercise, we apply Fisher Linear Discriminant as described in Chapter 3.8.2 of Duda et al. on the UCI Abalone dataset. A description of the dataset is given at the page https://archive.ics.uci.edu/ml/datasets/Abalone. The following two methods are provided for your convenience: \n",
      "\n",
      "\n",
      "* **`utils.Abalone.__init__(self)`** reads the Abalone data and instantiates two data matrices corresponding to: *infant (I)*, *non-infant (N)*.\n",
      "\n",
      "\n",
      "* **`utils.Abalone.plot(self,w)`** produces a histogram of the data when projected onto a vector `w`, and where each class is shown in a different color.\n",
      "\n",
      "\n",
      "Sample code that makes use of these two methods is given below. It loads the data, looks at the shape of instantiated matrices, and plots the projection on the first dimension of the data representing the length of the abalone."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import utils,numpy\n",
      "\n",
      "# Load the data\n",
      "abalone = utils.Abalone()\n",
      "\n",
      "# Print dataset size for each class\n",
      "print(abalone.I.shape, abalone.N.shape)\n",
      "\n",
      "# Project data on the first dimension\n",
      "w1 = numpy.array([1,0,0,0,0,0,0])\n",
      "abalone.plot(w1,'projection on the first dimension (length)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Implementation (10 + 5 + 5 = 20 P)\n",
      "\n",
      "* **Create a function `w = fisher(X1,X2)` that takes as input the data for two classes and returns the Fisher linear discriminant.**\n",
      "\n",
      "\n",
      "* **Create a function `objective(X1,X2,w)` that evaluates the objective defined in Equation 96 of Duda et al. for an arbitrary projection vector `w`.**\n",
      "\n",
      "\n",
      "* **Create a function `z = phi(X)` that returns a quadratic expansion for each data point `x` in the dataset. Such expansion consists of the vector `x` itself, to which we concatenate the vector of all pairwise products between elements of `x`.** In other words, letting $x = (x_1,\\dots,x_d)$ denote the $d$-dimensional data point, the quadratic expansion for this data point is a $d \\cdot (d+3)/2$ dimensional vector given by $\\phi(x) = (x_i)_{1 \\leq i \\leq d} \\cup (x_i x_j)_{1 \\leq i \\leq j \\leq d}$. For example, the quadratic expansion for $d=2$ is $(x_1,x_2,x_1^2,x_2^2,x_1 x_2)$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fisher(X1,X2):\n",
      "    ##### Replace by your code\n",
      "    import solutions\n",
      "    return solutions.fisher(X1,X2)\n",
      "    #####\n",
      "    \n",
      "def objective(X1,X2,w):\n",
      "    ##### Replace by your code\n",
      "    import solutions\n",
      "    return solutions.objective(X1,X2,w)\n",
      "    #####\n",
      "    \n",
      "def expand(X):\n",
      "    ##### Replace by your code\n",
      "    import solutions\n",
      "    return solutions.expand(X)\n",
      "    #####"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Analysis (5 + 5 = 10 P)\n",
      "\n",
      "* **Print value of the objective function and the histogram for several values of `w`:**\n",
      "\n",
      "  * `w` is a canonical coordinate vector for the first feature (length).\n",
      "  * `w` is the difference between the mean vectors of the two classes.\n",
      "  * `w` is the Fisher linear discriminant.\n",
      "  * `w` is the Fisher linear discriminant (after quadratic expansion of the data)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##### REPLACE BY YOUR CODE\n",
      "%matplotlib inline\n",
      "import solutions\n",
      "solutions.analysis()\n",
      "#####"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}